{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DimABSA - Subtask 1: Baseline Model\n",
    "## Dimensional Aspect Sentiment Regression (DimASR)\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "Predict Valence (1-9) and Arousal (1-9) scores for aspects in laptop reviews.\n",
    "\n",
    "**Example:**\n",
    "- Input: \"The battery life is excellent\" + Aspect: \"battery life\"\n",
    "- Output: Valence: 8.2, Arousal: 6.5\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset\n",
    "- Training samples: 4,076\n",
    "- Dev samples: 200\n",
    "- Format: JSONL (JSON Lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n",
      "PyTorch version: 2.9.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import Required Libraries\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration set!\n",
      "Training: datasets-subtask-1/eng_laptop_train_alltasks.jsonl\n",
      "Dev: datasets-subtask-1/eng_laptop_dev_task1.jsonl\n",
      "Model: bert-base-multilingual-cased\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "TRAIN_PATH = \"datasets-subtask-1/eng_laptop_train_alltasks.jsonl\"\n",
    "DEV_PATH = \"datasets-subtask-1/eng_laptop_dev_task1.jsonl\"\n",
    "\n",
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 3  # Start with 3 epochs for faster testing\n",
    "DROPOUT = 0.1\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Configuration set!\")\n",
    "print(f\"Training: {TRAIN_PATH}\")\n",
    "print(f\"Dev: {DEV_PATH}\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loading functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "def load_jsonl(filepath):\n",
    "    \"\"\"Load JSONL file\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "def jsonl_to_df(data):\n",
    "    \"\"\"Convert JSONL to DataFrame for Subtask 1\"\"\"\n",
    "    if 'Quadruplet' in data[0]:\n",
    "        # Training data (has quadruplets with VA scores)\n",
    "        df = pd.json_normalize(data, 'Quadruplet', ['ID', 'Text'])\n",
    "        df[['Valence', 'Arousal']] = df['VA'].str.split('#', expand=True).astype(float)\n",
    "        df = df.drop(columns=['VA', 'Category', 'Opinion'])\n",
    "        df = df.drop_duplicates(subset=['ID', 'Aspect'], keep='first')\n",
    "    elif 'Aspect' in data[0]:\n",
    "        # Dev/Test data (only has aspects, no VA scores)\n",
    "        df = pd.json_normalize(data, 'Aspect', ['ID', 'Text'])\n",
    "        df = df.rename(columns={df.columns[0]: \"Aspect\"})\n",
    "        df['Valence'] = 0  # Placeholder\n",
    "        df['Arousal'] = 0  # Placeholder\n",
    "    else:\n",
    "        raise ValueError(\"Invalid format\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Data loading functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading dev data...\n",
      "\n",
      "✅ Data loaded!\n",
      "Training samples: 4462\n",
      "Validation samples: 496\n",
      "Dev samples: 275\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "print(\"Loading training data...\")\n",
    "train_raw = load_jsonl(TRAIN_PATH)\n",
    "train_df = jsonl_to_df(train_raw)\n",
    "\n",
    "print(\"Loading dev data...\")\n",
    "dev_raw = load_jsonl(DEV_PATH)\n",
    "dev_df = jsonl_to_df(dev_raw)\n",
    "\n",
    "# Split training data (90% train, 10% validation)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"\\n Data loaded!\")\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Dev samples: {len(dev_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TRAINING DATA SAMPLE:\n",
      "==================================================\n",
      "        Aspect                      ID  \\\n",
      "251   computer     laptop_quad_dev_190   \n",
      "4516      unit  laptop_quad_train_2141   \n",
      "335       NULL     laptop_quad_dev_253   \n",
      "3286    device  laptop_quad_train_1230   \n",
      "753     screen    laptop_quad_test_236   \n",
      "\n",
      "                                                   Text  Valence  Arousal  \n",
      "251   if i had it to do over , i would not purchase ...     3.10     6.30  \n",
      "4516  after charging the unit for 2 hours i discover...     4.75     5.25  \n",
      "335   freezes with red lines across it , froze five ...     2.00     7.67  \n",
      "3286  a wonderful device with extremely clear display .     8.00     7.83  \n",
      "753                         the screen does look good .     6.62     6.62  \n",
      "\n",
      "Columns: ['Aspect', 'ID', 'Text', 'Valence', 'Arousal']\n",
      "\n",
      "Valence range: 1.00 - 8.83\n",
      "Arousal range: 3.83 - 8.83\n",
      "\n",
      "==================================================\n",
      "EXAMPLE REVIEWS:\n",
      "==================================================\n",
      "\n",
      "1. Text: if i had it to do over , i would not purchase this computer .\n",
      "   Aspect: computer\n",
      "   Valence: 3.10 | Arousal: 6.30\n",
      "\n",
      "2. Text: after charging the unit for 2 hours i discovered that the unit will only operate while the charger is connected .\n",
      "   Aspect: unit\n",
      "   Valence: 4.75 | Arousal: 5.25\n",
      "\n",
      "3. Text: freezes with red lines across it , froze five times the first afternoon .\n",
      "   Aspect: NULL\n",
      "   Valence: 2.00 | Arousal: 7.67\n"
     ]
    }
   ],
   "source": [
    "# Look at training data\n",
    "print(\"=\" * 50)\n",
    "print(\"TRAINING DATA SAMPLE:\")\n",
    "print(\"=\" * 50)\n",
    "print(train_df.head())\n",
    "print(f\"\\nColumns: {train_df.columns.tolist()}\")\n",
    "print(f\"\\nValence range: {train_df['Valence'].min():.2f} - {train_df['Valence'].max():.2f}\")\n",
    "print(f\"Arousal range: {train_df['Arousal'].min():.2f} - {train_df['Arousal'].max():.2f}\")\n",
    "\n",
    "# Show a few examples\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"EXAMPLE REVIEWS:\")\n",
    "print(\"=\" * 50)\n",
    "for i in range(3):\n",
    "    row = train_df.iloc[i]\n",
    "    print(f\"\\n{i+1}. Text: {row['Text']}\")\n",
    "    print(f\"   Aspect: {row['Aspect']}\")\n",
    "    print(f\"   Valence: {row['Valence']:.2f} | Arousal: {row['Arousal']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset class defined!\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Dataset class\n",
    "class VADataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for Valence-Arousal regression\n",
    "    Combines aspect and text into input: \"aspect: text\"\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, tokenizer, max_len=128):\n",
    "        self.sentences = dataframe[\"Text\"].tolist()\n",
    "        self.aspects = dataframe[\"Aspect\"].tolist()\n",
    "        self.labels = dataframe[[\"Valence\", \"Arousal\"]].values.astype(float)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Combine aspect and text\n",
    "        text = f\"{self.aspects[idx]}: {self.sentences[idx]}\"\n",
    "        \n",
    "        # Tokenize\n",
    "        encoded = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": encoded[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "print(\"Dataset class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Creating datasets...\n",
      "✅ Datasets created!\n",
      "Train batches: 279\n",
      "Val batches: 31\n",
      "Dev batches: 18\n",
      "\n",
      "Sample batch shapes:\n",
      "  Input IDs: torch.Size([16, 128])\n",
      "  Attention mask: torch.Size([16, 128])\n",
      "  Labels: torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Create datasets\n",
    "print(\"Creating datasets...\")\n",
    "train_dataset = VADataset(train_df, tokenizer, MAX_LENGTH)\n",
    "val_dataset = VADataset(val_df, tokenizer, MAX_LENGTH)\n",
    "dev_dataset = VADataset(dev_df, tokenizer, MAX_LENGTH)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\" Datasets created!\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Dev batches: {len(dev_loader)}\")\n",
    "\n",
    "# Test one batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"\\nSample batch shapes:\")\n",
    "print(f\"  Input IDs: {sample_batch['input_ids'].shape}\")\n",
    "print(f\"  Attention mask: {sample_batch['attention_mask'].shape}\")\n",
    "print(f\"  Labels: {sample_batch['labels'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model class defined!\n"
     ]
    }
   ],
   "source": [
    "# BERT-based regression model\n",
    "class VARegressor(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT-based model for predicting Valence and Arousal\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name=MODEL_NAME, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        self.backbone = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        hidden_size = self.backbone.config.hidden_size\n",
    "        self.regressor = nn.Linear(hidden_size, 2)  # 2 outputs: V and A\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERT outputs\n",
    "        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use [CLS] token representation\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Apply dropout and regressor\n",
    "        x = self.dropout(cls_output)\n",
    "        predictions = self.regressor(x)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "print(\" Model class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd257f35d5be4983beccd41748244bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model initialized!\n",
      "Total parameters: 177,854,978\n",
      "Trainable parameters: 177,854,978\n",
      "Model on device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "print(\"Initializing model...\")\n",
    "model = VARegressor().to(DEVICE)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\" Model initialized!\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation functions\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def eval_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "print(\" Training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "\n",
      "Epoch 1/3\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 279/279 [09:15<00:00,  1.99s/it, loss=1.2203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.9101\n",
      "Val Loss: 1.1106\n",
      "✅ New best model! Saving...\n",
      "\n",
      "Epoch 2/3\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 279/279 [08:58<00:00,  1.93s/it, loss=0.5706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8928\n",
      "Val Loss: 0.9914\n",
      "✅ New best model! Saving...\n",
      "\n",
      "Epoch 3/3\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 279/279 [09:05<00:00,  1.96s/it, loss=1.1120]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6594\n",
      "Val Loss: 0.8738\n",
      "✅ New best model! Saving...\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE!\n",
      "============================================================\n",
      "Best validation loss: 0.8738\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "print(\"=\" * 60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "training_history = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, DEVICE)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss = eval_epoch(model, val_loader, criterion, DEVICE)\n",
    "    \n",
    "    # Save history\n",
    "    training_history.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss\n",
    "    })\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        print(f\" New best model! Saving...\")\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Evaluation functions\n",
    "def get_predictions(model, dataloader, device):\n",
    "    \"\"\"Get predictions from model\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].cpu().numpy()\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask).cpu().numpy()\n",
    "            \n",
    "            all_preds.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    preds = np.vstack(all_preds)\n",
    "    labels = np.vstack(all_labels)\n",
    "    \n",
    "    return preds, labels\n",
    "\n",
    "def calculate_rmse(preds, labels):\n",
    "    \"\"\"Calculate RMSE for VA predictions\"\"\"\n",
    "    pred_v, pred_a = preds[:, 0], preds[:, 1]\n",
    "    gold_v, gold_a = labels[:, 0], labels[:, 1]\n",
    "    \n",
    "    # Combine V and A for RMSE calculation\n",
    "    gold_va = np.concatenate([gold_v, gold_a])\n",
    "    pred_va = np.concatenate([pred_v, pred_a])\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    squared_errors = (gold_va - pred_va) ** 2\n",
    "    rmse = np.sqrt(np.mean(squared_errors))\n",
    "    \n",
    "    # Normalized RMSE\n",
    "    rmse_norm = rmse / np.sqrt(128)\n",
    "    \n",
    "    # Calculate PCC\n",
    "    pcc_v = pearsonr(pred_v, gold_v)[0]\n",
    "    pcc_a = pearsonr(pred_a, gold_a)[0]\n",
    "    \n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'RMSE_normalized': rmse_norm,\n",
    "        'PCC_Valence': pcc_v,\n",
    "        'PCC_Arousal': pcc_a\n",
    "    }\n",
    "\n",
    "print(\"Evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model...\n",
      "\n",
      "Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "VALIDATION SET RESULTS:\n",
      "============================================================\n",
      "RMSE: 0.9348\n",
      "RMSE (normalized): 0.0826\n",
      "PCC Valence: 0.8374\n",
      "PCC Arousal: 0.6866\n",
      "\n",
      "============================================================\n",
      "SAMPLE PREDICTIONS:\n",
      "============================================================\n",
      "Predicted V  Predicted A  True V     True A     Error\n",
      "------------------------------------------------------------\n",
      "       4.07         6.21       3.12       6.12       0.95\n",
      "       7.80         7.69       7.67       7.50       0.22\n",
      "       7.74         7.74       7.50       7.50       0.35\n",
      "       7.46         7.32       7.12       7.00       0.47\n",
      "       7.81         7.73       8.12       8.25       0.60\n",
      "       3.89         6.04       3.83       6.33       0.30\n",
      "       6.49         6.34       5.67       5.67       1.06\n",
      "       7.59         7.25       7.25       7.38       0.36\n",
      "       5.26         5.89       5.33       5.17       0.72\n",
      "       7.80         7.73       7.75       7.62       0.12\n"
     ]
    }
   ],
   "source": [
    "# Load best model\n",
    "print(\"Loading best model...\")\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Get predictions on validation set\n",
    "print(\"\\nEvaluating on validation set...\")\n",
    "val_preds, val_labels = get_predictions(model, val_loader, DEVICE)\n",
    "val_metrics = calculate_rmse(val_preds, val_labels)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALIDATION SET RESULTS:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"RMSE: {val_metrics['RMSE']:.4f}\")\n",
    "print(f\"RMSE (normalized): {val_metrics['RMSE_normalized']:.4f}\")\n",
    "print(f\"PCC Valence: {val_metrics['PCC_Valence']:.4f}\")\n",
    "print(f\"PCC Arousal: {val_metrics['PCC_Arousal']:.4f}\")\n",
    "\n",
    "# Show some example predictions\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE PREDICTIONS:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Predicted V':<12} {'Predicted A':<12} {'True V':<10} {'True A':<10} {'Error'}\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(min(10, len(val_preds))):\n",
    "    pred_v, pred_a = val_preds[i]\n",
    "    true_v, true_a = val_labels[i]\n",
    "    error = np.sqrt((pred_v - true_v)**2 + (pred_a - true_a)**2)\n",
    "    print(f\"{pred_v:>11.2f} {pred_a:>12.2f} {true_v:>10.2f} {true_a:>10.2f} {error:>10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating predictions for dev set...\n",
      "✅ Predictions generated for 275 samples\n",
      "\n",
      "Sample predictions:\n",
      "                                                Text  \\\n",
      "0                    The touchscreen works very well   \n",
      "1                         I am so disappointed in HP   \n",
      "2  The keyboard is big enough to use for real typing   \n",
      "3                             I like the screen size   \n",
      "4            Lenovo is my favorite brand of computer   \n",
      "5  The sound is great and it's easy to use for us...   \n",
      "6             The quality for the price is excellent   \n",
      "7         The on screen keyboard is very easy to use   \n",
      "8            I got this laptop and am very impressed   \n",
      "9  I enjoyed the functionality of the trackpad , ...   \n",
      "\n",
      "                          Aspect   Valence   Arousal  \n",
      "0                    touchscreen  7.737481  7.465717  \n",
      "1                             HP  2.992138  6.917946  \n",
      "2                       keyboard  7.459754  7.129376  \n",
      "3                    screen size  7.539342  7.205931  \n",
      "4                         Lenovo  7.709945  7.513689  \n",
      "5                          sound  7.701700  7.642902  \n",
      "6                        quality  7.753933  7.674211  \n",
      "7             on screen keyboard  7.666661  7.496019  \n",
      "8                         laptop  7.755130  7.620813  \n",
      "9  functionality of the trackpad  7.701927  7.575125  \n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for dev set (for submission)\n",
    "print(\"\\nGenerating predictions for dev set...\")\n",
    "dev_preds, _ = get_predictions(model, dev_loader, DEVICE)\n",
    "\n",
    "# Add predictions to dev dataframe\n",
    "dev_df['Valence'] = dev_preds[:, 0]\n",
    "dev_df['Arousal'] = dev_preds[:, 1]\n",
    "\n",
    "# Clip values to [1, 9] range\n",
    "dev_df['Valence'] = dev_df['Valence'].clip(1.0, 9.0)\n",
    "dev_df['Arousal'] = dev_df['Arousal'].clip(1.0, 9.0)\n",
    "\n",
    "print(f\"Predictions generated for {len(dev_df)} samples\")\n",
    "print(\"\\nSample predictions:\")\n",
    "print(dev_df[['Text', 'Aspect', 'Valence', 'Arousal']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predictions saved to pred_eng_laptop.jsonl\n",
      "\n",
      "============================================================\n",
      "SUBMISSION FILE CREATED!\n",
      "============================================================\n",
      "File: pred_eng_laptop.jsonl\n",
      "You can now submit this file to the competition!\n"
     ]
    }
   ],
   "source": [
    "# Save predictions in competition format\n",
    "def save_predictions(df, output_path):\n",
    "    \"\"\"Save predictions in JSONL format for submission\"\"\"\n",
    "    # Sort by ID\n",
    "    df_sorted = df.sort_values(by=\"ID\")\n",
    "    \n",
    "    # Group by ID\n",
    "    grouped = df_sorted.groupby(\"ID\", sort=False)\n",
    "    \n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for gid, gdf in grouped:\n",
    "            record = {\n",
    "                \"ID\": gid,\n",
    "                \"Aspect_VA\": []\n",
    "            }\n",
    "            for _, row in gdf.iterrows():\n",
    "                record[\"Aspect_VA\"].append({\n",
    "                    \"Aspect\": row[\"Aspect\"],\n",
    "                    \"VA\": f\"{row['Valence']:.2f}#{row['Arousal']:.2f}\"\n",
    "                })\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "    \n",
    "    print(f\"Predictions saved to {output_path}\")\n",
    "\n",
    "# Save predictions\n",
    "output_file = \"pred_eng_laptop.jsonl\"\n",
    "save_predictions(dev_df, output_file)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUBMISSION FILE CREATED!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"File: {output_file}\")\n",
    "print(f\"You can now submit this file to the competition!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
